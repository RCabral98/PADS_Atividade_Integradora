{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19200d04",
   "metadata": {},
   "source": [
    "![Insper](https://github.com/danielscarvalho/Insper-DS-Dicas/blob/master/Insper-Logo.png?raw=true)\n",
    "\n",
    "# Insper Pós-Graduação\n",
    "## Programa Avançado em Data Science e Decisão [»](https://www.insper.edu.br/pos-graduacao/programas-avancados/programa-avancado-em-data-science-e-decisao/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd53497e",
   "metadata": {},
   "source": [
    "# Atividade Integradora\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89785bb",
   "metadata": {},
   "source": [
    "### Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee571d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dfply import *\n",
    "import altair as alt\n",
    "import missingno as msno\n",
    "from ydata_profiling import ProfileReport\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050ff5a",
   "metadata": {},
   "source": [
    "### Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b82d503",
   "metadata": {},
   "source": [
    "Leitura da base de dados e do dicionários de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b3424",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cs_bisnode_panel.csv\")\n",
    "dicionario_de_dados_0 = pd.read_excel(\"bisnode_variable_names.xls\", header=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660148f3",
   "metadata": {},
   "source": [
    "Visualização inicial da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ed1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fbc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eec859",
   "metadata": {},
   "source": [
    "## Limpeza dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6a7773",
   "metadata": {},
   "source": [
    "### Dicionário de dados - Limpeza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ae71cf",
   "metadata": {},
   "source": [
    "Ao carregar o dicionário de dados a primeira coluna pega seu nome da quarta linha da tabela (argumento `header=4` acima). As outras três colunas são nomeadas abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dad806",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_de_dados_1 = dicionario_de_dados_0.rename({'Unnamed: 1': 'description',\n",
    "                                                      'Unnamed: 2': 'type',\n",
    "                                                      'Unnamed: 3': 'footnote'},\n",
    "                                                     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd2c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_de_dados_1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048efc9e",
   "metadata": {},
   "source": [
    "Então, retiramos as linhas não relevantes para a análise, incluindo linhas totalmente em branco e uma linha com informação de versão da base de dados: \n",
    " - `v 0.92. 2021-02-04`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5fc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_de_dados = dicionario_de_dados_1\\\n",
    "                       .drop(index=54)\\\n",
    "                       .dropna(how=\"all\")\\\n",
    "                       .reset_index()\\\n",
    "                       .drop('index', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89116b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_de_dados.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4a7f09",
   "metadata": {},
   "source": [
    "## Dados\n",
    "### Removendo colunas específicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a70236",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['COGS', 'finished_prod', 'net_dom_sales', 'net_exp_sales', 'wages', 'D', 'begin', 'end'] # além das variáveis da questões, removido begin e end, pois utilizaremos apenas o year \n",
    "\n",
    "data.drop(columns=columns_to_remove, inplace=True)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501c7584",
   "metadata": {},
   "source": [
    "### Removendo dados do ano 2016:\n",
    "---\n",
    "\n",
    "Registros do ano de 2016 são removidos do conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"year\"]!=2016].copy()\n",
    "data[\"year\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb345531",
   "metadata": {},
   "source": [
    "Dados destas colunas precisam estar em formato de datetime para serem operados corretamente, então vamos converte-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f86763",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_data = [\"founded_date\", \"exit_date\"]\n",
    "\n",
    "data.dtypes[colunas_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in colunas_data:\n",
    "    data[column] = pd.to_datetime(data[column], format=\"%Y-%m-%d\")\n",
    "\n",
    "data[colunas_data].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a51a40",
   "metadata": {},
   "source": [
    "### Missing data:\n",
    "---\n",
    "\n",
    "Vamos verificar dados faltando do banco de dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2df98a",
   "metadata": {},
   "source": [
    "Criação de função para analisar os dados faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c46b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_missing(df):\n",
    "    \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n",
    "    \n",
    "    variables = []\n",
    "    dtypes = []\n",
    "    count = []\n",
    "    unique = []\n",
    "    missing = []\n",
    "    pc_missing = []\n",
    "    \n",
    "    for item in df.columns:\n",
    "        variables.append(item)\n",
    "        dtypes.append(df[item].dtype)\n",
    "        count.append(len(df[item]))\n",
    "        unique.append(len(df[item].unique()))\n",
    "        missing.append(df[item].isna().sum())\n",
    "        pc_missing.append(round((df[item].isna().sum() / len(df[item])) * 100, 2))\n",
    "\n",
    "    output = pd.DataFrame({\n",
    "        'variable': variables, \n",
    "        'dtype': dtypes,\n",
    "        'count': count,\n",
    "        'unique': unique,\n",
    "        'missing': missing, \n",
    "        'pc_missing': pc_missing\n",
    "    })    \n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab9a4c5",
   "metadata": {},
   "source": [
    "Verificando dados com maior falta de informações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc51f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = show_missing(data).sort_values(\"pc_missing\", ascending=False, ignore_index = True)\n",
    "\n",
    "index_full_data = list(missing_data[missing_data[\"missing\"]==0].index)\n",
    "\n",
    "missing_data.drop(labels=index_full_data, axis=\"index\", inplace=True)\n",
    "\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111674f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_val_columns = missing_data[\"variable\"][missing_data[\"pc_missing\"]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ca687",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(data[missing_val_columns], figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c3b369",
   "metadata": {},
   "source": [
    "## Tratamento de dados ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f5267",
   "metadata": {},
   "source": [
    "- exit_year(86.03%) e exit_date (79.80%): Será utilizado apenas o exit_year para saber se a empresa estava ativa no ano de análise. Quando o exit_year estiver ausente, vamos procurar se tem valor na exit_date para pegar o ano de encerramento da empresa. Em seguida, vamos excluir a variével exit_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quando o exit_year estiver ausente, pegue o ano de exit_date\n",
    "data.loc[data['exit_year'].isna(), 'exit_year'] = pd.to_datetime(data['exit_date']).dt.year\n",
    "\n",
    "# Substituir valores NaN em exit_year por \"-\"\n",
    "data['exit_year'] = data['exit_year'].fillna('-')\n",
    "\n",
    "# Excluir a coluna exit_date\n",
    "data = data.drop(columns='exit_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942cb23",
   "metadata": {},
   "source": [
    "### 1. Tratamento de dados com menos de 4% de dados ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b33b6",
   "metadata": {},
   "source": [
    "- founded_year (20.2%): essa variável pode ser obtida a partir da variável \"founded_date\". Como a variável \"founded_date\" apenas 0.02% de dados ausente, a found_year será formada a partir do ano da founded_year e depois vamos excluir a coluna founded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce740c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas onde 'founded_date' é NaN\n",
    "data = data.dropna(subset=['founded_date'])\n",
    "\n",
    "# Extraindo o ano de 'founded_date' e substituindo os valores ausentes em 'founded_year'\n",
    "data['founded_year'] = data['founded_date'].dt.year\n",
    "\n",
    "# Descartanto a coluna 'founded_date', pois utilizar apemas o ano de fundação da empresa é suficiente\n",
    "data = data.drop(columns=['founded_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbdcad4",
   "metadata": {},
   "source": [
    "Analisando percentuais de missing após os tratamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb741e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data2 = show_missing(data).sort_values(\"pc_missing\", ascending=False, ignore_index = True)\n",
    "\n",
    "index_full_data = list(missing_data2[missing_data2[\"missing\"]==0].index)\n",
    "\n",
    "missing_data2.drop(labels=index_full_data, axis=\"index\", inplace=True)\n",
    "\n",
    "missing_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ebc62",
   "metadata": {},
   "source": [
    "- todos os dados com <4% de dados ausentes: Vamos iniciar tratando os dados que estejam com menos de 4% de dados ausentes. Primeiramente, serão analisados se as linhas das colunas com menos de 4% de dados ausentes coincidem ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0255d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas com menos de 4% de dados ausentes\n",
    "\n",
    "cols = list(missing_data2[\"variable\"][missing_data2[\"pc_missing\"]<5.0])\n",
    "\n",
    "# Verificar quais linhas possuem dados ausentes nessas colunas\n",
    "\n",
    "missing_rows = data[cols].isnull().any(axis=1)      \n",
    "\n",
    "# Calcular o percentual de linhas com dados ausentes\n",
    "\n",
    "pc_missing_rows = 100 * missing_rows.sum() / len(data)\n",
    "\n",
    "print(f\"Percentual de linhas com dados ausentes em pelo menos uma das colunas mencionadas: {pc_missing_rows:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd4700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo variáveis com menos de 5% de dados ausentes\n",
    "removable_na_columns = list(missing_data2[\"variable\"][missing_data2[\"pc_missing\"]<5.0])\n",
    "\n",
    "data.dropna(subset=removable_na_columns, ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d64025",
   "metadata": {},
   "source": [
    "Observando os valores de missing após os tratamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d44845",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_3 = show_missing(data).sort_values(\"pc_missing\", ascending=False, ignore_index = True)\n",
    "\n",
    "index_full_data = list(missing_data_3[missing_data_3[\"missing\"]==0].index)\n",
    "\n",
    "missing_data_3.drop(labels=index_full_data, axis=\"index\", inplace=True)\n",
    "\n",
    "missing_data_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b0eb5",
   "metadata": {},
   "source": [
    "Analisando dados ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a826f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793d9a0a",
   "metadata": {},
   "source": [
    "Analisando variáveis labor_avg e birth_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e767f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Plotando um histograma para 'labor_avg'\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data['labor_avg'].dropna(), bins=30, color='blue', alpha=0.7)\n",
    "plt.title('Distribuição de labor_avg')\n",
    "plt.xlabel('labor_avg')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "# Plotando um histograma para 'birth year CEO'\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data['birth_year'].dropna(), bins=30, color='green', alpha=0.7)\n",
    "plt.title('Distribuição de birth year CEO')\n",
    "plt.xlabel('birth year CEO')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebdc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando e mostrando a skewness (assimetria) das variáveis\n",
    "print(f\"Assimetria de labor_avg: {data['labor_avg'].skew()}\")\n",
    "print(f\"Assimetria de birth year CEO: {data['birth_year'].skew()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando o estilo do Seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Boxplot para 'labor_avg'\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=data['labor_avg'], color='blue')\n",
    "plt.title('Boxplot de labor_avg')\n",
    "\n",
    "# Boxplot para 'birth year CEO'\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=data['birth_year'], color='green')\n",
    "plt.title('Boxplot de birth year CEO')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27746497",
   "metadata": {},
   "source": [
    "## Tratar demais variáveis com MICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c70f20",
   "metadata": {},
   "source": [
    "Os demais valores ausentes serão preenchidos utilizando o método MICE (Multiple Imputation by Chained Equations) com a biblioteca 'IterativeImputer' do sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2776a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mice = data.copy()\n",
    "df_mice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a91364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cópia do df_mice para converter em dummies\n",
    "df_mice2 = df_mice.copy()\n",
    "df_mice2 = pd.get_dummies(df_mice2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145b91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Input de MICE e preenche NaN \n",
    "\n",
    "mice_imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
    "df_mice_imputed = pd.DataFrame(mice_imputer.fit_transform(df_mice2), columns=df_mice2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mice_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c78adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_3 = show_missing(df_mice_imputed).sort_values(\"pc_missing\", ascending=False, ignore_index = True)\n",
    "\n",
    "index_full_data_3 = list(missing_data_3[missing_data_3[\"missing\"]==0].index)\n",
    "\n",
    "missing_data_3.drop(labels=index_full_data_3, axis=\"index\", inplace=True)\n",
    "\n",
    "missing_data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae57b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando dados imputados \n",
    "\n",
    "#MICE imputacao\n",
    "fig = plt.Figure()\n",
    "null_values = data['labor_avg'].isnull() \n",
    "fig = df_mice_imputed.plot(x='sales', y='labor_avg', kind='scatter',\n",
    "                           c=null_values, cmap='winter', s = 15,\n",
    "                           title='MICE Imputation', colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mice_imputed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d782f3",
   "metadata": {},
   "source": [
    "Reverter o processo de pd.get_dummies com base no df_mice_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário que contém as colunas originais e suas respectivas colunas transformadas em dummies\n",
    "categorical_cols_transformed = {\n",
    "    'exit_year': [col for col in df_mice_imputed.columns if 'exit_year' in col],\n",
    "    'gender': [col for col in df_mice_imputed.columns if 'gender_' in col],\n",
    "    'origin': [col for col in df_mice_imputed.columns if 'origin_' in col],\n",
    "    'region_m': [col for col in df_mice_imputed.columns if 'region_m_' in col]\n",
    "}\n",
    "\n",
    "# Para cada coluna original, encontrar a coluna dummy com o valor mais alto (1) e restaurar a coluna original\n",
    "for original_col, dummies in categorical_cols_transformed.items():\n",
    "    df_mice_imputed[original_col] = df_mice_imputed[dummies].idxmax(axis=1).str.replace(original_col + \"_\", \"\")\n",
    "    df_mice_imputed.drop(dummies, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02302b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mice_imputed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93fa20a",
   "metadata": {},
   "source": [
    "Vemos que temos dados de venda com erros, onde há valores negativos para vendas, vamos tratar estes dados substituindo valores negativos por nulos (valor = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121e585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remodelando os dados de vendas para corrigir os erros:\n",
    "\n",
    "for x in [\"sales\"]:\n",
    "    df_mice_imputed[x] = np.where(df_mice_imputed[x]<0, 0, df_mice_imputed[x])\n",
    "\n",
    "df_mice_imputed['fechado'] = condition.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99abaf0a",
   "metadata": {},
   "source": [
    "### Criando coluna para Variável Dependente:\n",
    "---\n",
    "\n",
    "- Vamos operar com o conceito de \"atividade\", empresas que não tiveram atividade por mais de 2 anos são consideradas \"inativas\".\n",
    "\n",
    "Obs.: ativa = 0, inativa = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7111d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by company and year\n",
    "df_mice_imputed.sort_values(by=['comp_id', 'year'], inplace=True)\n",
    "\n",
    "# Create shifted columns to check sales in the following 2 years\n",
    "conditions_x1 = [((df_mice_imputed['comp_id'] == df_mice_imputed['comp_id'].shift(-1)) &\n",
    "                  (df_mice_imputed['year'] == df_mice_imputed['year'].shift(-1) - 1)),\n",
    "\n",
    "                 ((df_mice_imputed['comp_id'] != df_mice_imputed['comp_id'].shift(-1)) |\n",
    "                  df_mice_imputed['year'] != df_mice_imputed['year'].shift(-1))]\n",
    "\n",
    "values_x1 = [df_mice_imputed['sales'].shift(-1),\n",
    "             np.nan]\n",
    "\n",
    "df_mice_imputed['sales_x1'] = pd.Series(np.select(conditions_x1, values_x1)).fillna(0)\n",
    "\n",
    "\n",
    "conditions_x2 = [\n",
    "    ((df_mice_imputed['comp_id'] == df_mice_imputed['comp_id'].shift(-1)) &   \n",
    "     (df_mice_imputed['year'] == df_mice_imputed['year'].shift(-1) - 2)),\n",
    "\n",
    "    ((df_mice_imputed['comp_id'] == df_mice_imputed['comp_id'].shift(-2)) &\n",
    "     (df_mice_imputed['year'] == df_mice_imputed['year'].shift(-2) - 2)),\n",
    "\n",
    "    True\n",
    "]\n",
    "\n",
    "values_x2 = [df_mice_imputed['sales'].shift(-1),\n",
    "             df_mice_imputed['sales'].shift(-2),\n",
    "             np.nan]\n",
    "\n",
    "df_mice_imputed['sales_x2'] = pd.Series(np.select(conditions_x2, values_x2)).fillna(0)\n",
    "\n",
    "\n",
    "# Create a condition to identify companies that ceased to operate \n",
    "# (sem vendas por mais de 2 anos)\n",
    "condition = ((df_mice_imputed['sales_x1'] == 0) & (df_mice_imputed['sales_x2'] == 0)) \n",
    "\n",
    "# Create a new 'dependente' column with 1 for ceased companies and 0 otherwise\n",
    "df_mice_imputed['fechado'] = condition.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8dd79",
   "metadata": {},
   "source": [
    "Vamos conferir os valores da variavel dependente para algumas empresas do dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de colunas para avaliação:\n",
    "check_list = [\"comp_id\", \"year\", \"exit_year\", \"sales\", \"sales_x1\", \"sales_x2\", \"dependente\"]\n",
    "\n",
    "filtro = df_mice_imputed[check_list]\n",
    "filtro_sub = filtro[(filtro[\"comp_id\"] == 464021159936) | (filtro[\"comp_id\"] == 1001541)]\n",
    "\n",
    "filtro_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mice_imputed[check_list].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e7b99a",
   "metadata": {},
   "source": [
    "Corrigimos os valores de vendas negativas, e assim também de dependentes que pudessem estar sendo afetados.\n",
    "\n",
    "Vamos agora:\n",
    " \n",
    "- tratar por fim os casos em que não há informações de venda para um próximo ano (por não haver um próximo ano;\n",
    "\n",
    "- criar uma coluna de vendas em \"Log\" para tratar a assimetria dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1daf1bd",
   "metadata": {},
   "source": [
    "Vamos averiguar agora os anos em que as empresas tiveram atividade e inatividade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde17eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo 'comp_id' para float antes de agrupar\n",
    "df_mice_imputed['comp_id'] = df_mice_imputed['comp_id'].astype(float)\n",
    "\n",
    "data_grouped = df_mice_imputed.groupby('comp_id')\n",
    "\n",
    "#Contando anos de acompanhamento\n",
    "comp_years = data_grouped['year'].count()\n",
    "\n",
    "#Contando anos com vendas\n",
    "sales_years = data_grouped.apply(lambda group: (group['sales'] > 0).sum())\n",
    "\n",
    "#contando anos sem vendas\n",
    "no_sales_years = data_grouped.apply(lambda group: (group['sales'] == 0).sum())\n",
    "\n",
    "#Contando anos de \"inatividade\"\n",
    "inative_years = data_grouped.apply(lambda group: (group['dependente'] == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9dbe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "activity_df = pd.DataFrame({\"Total years\":comp_years,\n",
    "                            \"Sales years\":sales_years, \n",
    "                            \"No sales years\":no_sales_years,\n",
    "                            \"Inative years\":inative_years}).reset_index()\n",
    "\n",
    "activity_df['comp_id'] = activity_df['comp_id'].astype(float)\n",
    "activity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5026b4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b8e402",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Criando dataframe apenas com os dados do ano de 2012\n",
    "\n",
    "data_2012 = df_mice_imputed[df_mice_imputed['year'] == 2012].copy()\n",
    "data_2012.year.unique() # verificando coluna de ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# considerando apenas sales > 1000 e < 10000000\n",
    "\n",
    "data_2012 = data_2012[(data_2012['sales'] > 1000) & (data_2012['sales'] < 10000000) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee829d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando valores da coluna year_exit\n",
    "\n",
    "data_2012['exit_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b517261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check list\n",
    "check_list = [\"comp_id\", \"year\", \"exit_year\", \"sales\", \"sales_x1\", \"sales_x2\", \"dependente\"]\n",
    "\n",
    "# Converta \"-\" para NaN\n",
    "data_2012[\"exit_year\"].replace(\"-\", np.nan, inplace=True)\n",
    "\n",
    "# Converta a coluna para float\n",
    "data_2012[\"exit_year\"] = data_2012[\"exit_year\"].astype(float)\n",
    "\n",
    "# Filtre o dataframe\n",
    "filtro = data_2012[check_list]\n",
    "filtro_sub = filtro[filtro[\"exit_year\"] < 2012]\n",
    "filtro_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d529e1",
   "metadata": {},
   "source": [
    "Conforme apresentado acima, algumas empresas que encerraram suas atividades antes de 2012 apresentaram vendas em 2012 e nos anos seguintes. Entretanto, na nossa análise, verificamos se a empresa está ativa em 2012 com base na variável \"exit_year\". Essas empresas podem terem sido reabertas ou pode ser um erro na base, mas, como são poucos casos, vamos excluir essas empresas que encerraram a atividade antes de 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d3884d",
   "metadata": {},
   "source": [
    "Verificando as empresas que encerraram as atividades em 2012. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb6ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check list\n",
    "check_list = [\"comp_id\", \"year\", \"exit_year\", \"sales\", \"sales_x1\", \"sales_x2\", \"dependente\"]\n",
    "\n",
    "# Converta \"-\" para NaN\n",
    "data_2012[\"exit_year\"].replace(\"-\", np.nan, inplace=True)\n",
    "\n",
    "# Converta a coluna para float\n",
    "data_2012[\"exit_year\"] = data_2012[\"exit_year\"].astype(float)\n",
    "\n",
    "# Filtre o dataframe\n",
    "filtro = data_2012[check_list]\n",
    "filtro_sub = filtro[filtro[\"exit_year\"] == 2012]\n",
    "filtro_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df004626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somar as colunas sales_x1 e sales_x2\n",
    "total_sales_x1 = filtro_sub['sales_x1'].sum()\n",
    "total_sales_x2 = filtro_sub['sales_x2'].sum()\n",
    "\n",
    "print(f\"Total de sales_x1: {total_sales_x1}\")\n",
    "print(f\"Total de sales_x2: {total_sales_x2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73423d0",
   "metadata": {},
   "source": [
    "Algumas empresas que encerraram as atividades até 31/12/2012 tiveram sales durante o ano de 2012, mas não tiveram vendas no ano seguinte, conforme o esperado. Como nosso objetivo é prever as empresas que estavam ativas em 31/12/2012 e tiveram suas atividades encerradas em até dois anos, as empresas que encerraram as atividades em 2012 serão retiradas da base também. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirando empresas que encerraram a atitidade até 2012, portanto não estavam ativa na nossa data base de análise\n",
    "data_2012 = data_2012.copy()\n",
    "data_2012 = data_2012[data_2012['exit_year'] > 2012]\n",
    "\n",
    "# Verificando valores da coluna year_exit\n",
    "data_2012['exit_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9303a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar apenas colunas numéricas para calcular skewness\n",
    "numeric_cols = data_2012.select_dtypes(include=[np.number]).columns # Avaliar a simetria das variáveis\n",
    "\n",
    "# Avaliar a simetria das colunas numéricas\n",
    "skewness_values = data_2012[numeric_cols].skew()\n",
    "\n",
    "# Ordenando os valores de skewness do maior para o menor\n",
    "sorted_skewness_values = skewness_values.sort_values(ascending=False)\n",
    "\n",
    "# Mostrando os valores de skewness ordenados\n",
    "print(sorted_skewness_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificando colunas com skewness significativamente diferente de zero\n",
    "cols_to_transform = skewness_values[skewness_values.abs() > 0.5].index\n",
    "print(cols_to_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c769632",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Nas estatísticas descritivas abaixo, observa-se que a média é maior que o terceiro quartil, indicando uma distribuição bastante assimétrica. Criamos então uma com o logarítmo de `sales` para auxiliar na análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7be6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_2012['sales'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d9ae36",
   "metadata": {},
   "source": [
    "A coluna log_sales mostra que, embora muitas empresas tenham vendas relativamente baixas (indicado por um logaritmo de vendas próximo ou igual a zero), há empresas que se destacam com vendas substancialmente mais altas. A transformação logarítmica ajudou a reduzir a assimetria e a concentrar os dados, tornando-os mais tratáveis para análise estatística e modelagem. No entanto, a presença de uma assimetria à esquerda ainda é evidente, sugerindo que muitas empresas no dataset têm vendas baixas ou nulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a coluna sales usando log\n",
    "data_2012.loc[:,'log_sales'] = data_2012.sales\\\n",
    "                                        .apply(lambda x: math.log(x)\\\n",
    "                                               if x != 0\\\n",
    "                                               else 0)\n",
    "\n",
    "# Mostrando estatísticas descritivas da coluna log_sales\n",
    "print(data_2012.log_sales.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317891e2",
   "metadata": {},
   "source": [
    "Comparando a distribuição da variável sales e log_sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando histogramas\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Histograma de sales\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data_2012['sales'], bins=50, color='blue', edgecolor='black')\n",
    "plt.title('Histograma de Sales')\n",
    "plt.xlabel('Sales')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "# Histograma de log_sales\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data_2012['log_sales'], bins=50, color='green', edgecolor='black')\n",
    "plt.title('Histograma de Log de Sales')\n",
    "plt.xlabel('Log Sales')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895cc959",
   "metadata": {},
   "source": [
    "### Criação de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Idade da Empresa:\n",
    "data_2012['company_age'] = 2012 - data_2012['founded_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Alavancagem Financeira:\n",
    "#data_2012['financial_leverage'] = data_2012['curr_liab'] / data_2012['share_eq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ab09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Liquidez:\n",
    "#data_2012['liquidity_ratio'] = data_2012['liq_assets'] / data_2012['curr_liab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca40434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Eficiência:\n",
    "#data_2012['efficiency'] = data_2012['sales'] / data_2012['labor_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fe53c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Tamanho da Empresa (exemplo baseado em vendas):\n",
    "#sales_bins = [0, 1e6, 1e9, float('inf')]  # Exemplo de categorias: <1M, 1M-1B, >1B\n",
    "#labels = ['small', 'medium', 'large']\n",
    "#data_2012['company_size'] = pd.cut(data_2012['sales'], bins=sales_bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a0d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Margem de Lucro:\n",
    "#data_2012['profit_margin'] = data_2012['profit_loss_year'] / data_2012['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab3294",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2012 = data_2012.drop(columns=['sales_x1','sales_x2', 'exit_year', 'year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c8a0a",
   "metadata": {},
   "source": [
    "## Matriz de correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar todas as colunas exceto \"dependente\"\n",
    "cols = [col for col in data_2012.columns if col != \"dependente\"]\n",
    "\n",
    "# Dividir as colunas em dois grupos\n",
    "half = len(cols) // 2\n",
    "group1 = cols[:half] + [\"dependente\"]\n",
    "group2 = cols[half:] + [\"dependente\"]\n",
    "\n",
    "# Considerar apenas colunas numéricas\n",
    "group1 = [col for col in group2 if data_2012[col].dtype in ['int64', 'float64']]\n",
    "group2 = [col for col in group2 if data_2012[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Criar as duas matrizes de correlação\n",
    "correlation_matrix1 = data_2012[group1].corr()\n",
    "correlation_matrix2 = data_2012[group2].corr()\n",
    "\n",
    "# Visualizar a primeira matriz de correlação\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.heatmap(correlation_matrix1, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix - Group 1')\n",
    "plt.show()\n",
    "\n",
    "# Visualizar a segunda matriz de correlação\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.heatmap(correlation_matrix2, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix - Group 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a79a3a",
   "metadata": {},
   "source": [
    "missing_data_4 = show_missing(data_2012).sort_values(\"pc_missing\", ascending=False, ignore_index = True)\n",
    "\n",
    "full_index = list(missing_data_3[missing_data_3[\"missing\"]==0].index)\n",
    "\n",
    "missing_data_4.drop(labels=full_index, axis=\"index\", inplace=True)\n",
    "\n",
    "missing_data_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46871d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2012.to_csv(\"data_2012.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2012.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f9f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_2012.to_excel(\"data_2012.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/opt/conda/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
