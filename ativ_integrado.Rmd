---
title: "Atividade Integradora 1 Trimestre"
output: html_document
date: "2023-09-06"
---

```{r setup, include=FALSE}

library(tidyverse)
library(dbplyr)
library(ggplot2)      #Biblioteca para plots gráficos
library(rpart)        #Biblioteca para árvore de regressão
library(rpart.plot)   
library(skimr)        #Biblioteca para overview dos dados
library(rsample)
library(ranger)       #Biblioteca para Random Forest
library(janitor)      #Biblioteca pra remoção de colunas
library(glmnet)       #Biblioteca para modelos de regressão com encolhimento (Ridge, LASSO, elastic-net)
library(plotmo)       #Plotar os gráficos dos coeficientes Ridge
library(pROC)
library(caret)        #Biblioteca para confusion matrix

```

# Lendo os dados

```{r}
df <- read.csv("data_2012.csv")

skim(df)
summary(df)

```

# visualizações iniciais:

```{r}

```

# Vamos considerar os seguintes modelos:

1.  Linear regresion
2.  shrinkage methods
3.  Random Forest
4.  Boosting methods

# Treinamento x Teste

```{r}
df <- df %>% 
  mutate(fechado = factor(fechado, levels = c(0, 1)))
```


```{r}
set.seed(123)

splits <- initial_split(df, prop = .8)

treinamento <- training(splits)
teste <- testing(splits)
```

# Tabela de comparação dos modelos de predição

```{r}
resultados <- tibble(modelo = c("Logistic", "Shrinkage", 
                                "Random Forest", "Boosting"),
                     accuracy = NA,
                     AUC = NA,
                     sensitivity = NA,
                     specificity = NA)
```

Obs.: As métricas escolhidas para avaliar o desempenho foram a acurácia geral, a AUC da curva ROC, sensibilidade (verdadeiro positivo) e specificidae (verdadeiro negativo).

(Escrever mais detalhes de escolha das métricas)

Váriáveis identificadas para relevância:
```{r}

prediction_vars <- c()

formula <- paste("fechado ~", paste(prediction_vars, collapse = " + "))
```

# modelos:

## Modelo 1

Regressão Logística

```{r}
resultados_logist <- tibble(modelo = c("primeiro", "segundo"),
                            accuracy = NA,
                            AUC = NA,
                            sensitivity = NA,
                            specificity = NA)
```


Primeira iteração:
Todas as variáveis menos comp_id

```{r}
# Fit
fit_logistic <- glm(fechado ~ .-comp_id, data = treinamento, family = binomial)

# Predição probabilidade de ser 1
depend_predict_logistic <- predict(fit_logistic, newdata = teste, type = "response")

# Convertendo probabilidade para binário:
depend_predict_bin <- ifelse(depend_predict_logistic > 0.5, 1, 0)

# Calculando acurácia:
accuracy <- mean(depend_predict_bin == teste$fechado)

```

```{r}
# Create a ROC curve object
roc_obj <- roc(teste$fechado, depend_predict_logistic)

# Calculate AUC
auc_value <- auc(roc_obj)


# Calculate sensitivity and specificity
depend_predict_bin <- as.factor(depend_predict_bin)
teste$fechado <- as.factor(teste$fechado)

# Cria matrix de confusão
conf_matrix <- confusionMatrix(depend_predict_bin, teste$fechado)

sensitivity_value <- conf_matrix$byClass["Sensitivity"]
specificity_value <- conf_matrix$byClass["Specificity"]
```

```{r}
# Salvando resultados:
resultados_logist$accuracy[resultados_logist$modelo == "primeiro"] <- accuracy
resultados_logist$AUC[resultados_logist$modelo == "primeiro"] <- auc_value
resultados_logist$sensitivity[resultados_logist$modelo == "primeiro"] <- sensitivity_value
resultados_logist$specificity[resultados_logist$modelo == "primeiro"] <- specificity_value
```


Segunda iteração:
Grupo de variáveis "prediction_vars"

```{r}
# Fit
fit_logistic <- glm(formula, data = treinamento, family = binomial)

# Predição probabilidade de ser 1
depend_predict_logistic <- predict(fit_logistic, newdata = teste, type = "response")

# Convertendo probabilidade para binário:
depend_predict_bin <- ifelse(depend_predict_logistic > 0.5, 1, 0)

# Calculando acurácia:
accuracy <- mean(depend_predict_bin == teste$fechado)
```

```{r}
# Create a ROC curve object
roc_obj <- roc(teste$fechado, depend_predict_logistic)

# Calculate AUC
auc_value <- auc(roc_obj)


# Calculate sensitivity and specificity
depend_predict_bin <- as.factor(depend_predict_bin)
teste$fechado <- as.factor(teste$fechado)

# Cria matrix de confusão
conf_matrix <- confusionMatrix(depend_predict_bin, teste$fechado)

sensitivity_value <- conf_matrix$byClass["Sensitivity"]
specificity_value <- conf_matrix$byClass["Specificity"]
```

```{r}
# Salvando resultados:
resultados_logist$accuracy[resultados_logist$modelo == "primeiro"] <- accuracy
resultados_logist$AUC[resultados_logist$modelo == "primeiro"] <- auc_value
resultados_logist$sensitivity[resultados_logist$modelo == "primeiro"] <- sensitivity_value
resultados_logist$specificity[resultados_logist$modelo == "primeiro"] <- specificity_value
```

### Melhores resultados do modelo Logístico:

```{r}
best_row_idx <- which.max(resultados_logist$AUC)
best_model <- resultados_logist[best_row_idx, ]


resultados$accuracy[resultados$modelo == "Logistic"] <- best_model$accuracy
resultados$AUC[resultados$modelo == "Logistic"] <- best_model$AUC
resultados$sensitivity[resultados$modelo == "Logistic"] <- best_model$sensitivity
resultados$specificity[resultados$modelo == "Logistic"] <- best_model$specificity
```


## Modelo 2

Encolhimento - LASSO

```{r}
# Preparando para glmnet ------------------------------

#str(treinamento)

#desconsiderando variável dependente:

x <- as.matrix(treinamento[, -which(names(treinamento)=="fechado")]) 
y <- treinamento$fechado

x_test <- as.matrix(teste[, -which(names(treinamento)=="fechado")])
y_test <- teste$fechado

#definindo sequência de lambda
lambda_seq <- 10^seq(10, -2, length=100)
```


```{r}
# Fit
fit_lasso <- glmnet(x, y, alpha = 1)

#plot_glmnet(fit_lasso)

# Cross-Validation
cv_lasso <- cv.glmnet(x, y, alpha = 1)

# Escolhendo melhor valor de lambda com a cross validadtion
lambda_lasso <- cv_lasso$lambda.1se #melhor valor de lambda (no caso 1 desv. pad. do min)



# Predição
depend_predict_lasso <- predict(fit_lasso,
                                newx = x_test,
                                s = lambda_lasso)

# Calculo EQM
EQM_lasso <- mean((y_test - depend_predict_lasso)^2)

# Calculo R quadrado
r2 <- 1 - (EQM_lasso/var(y_test))

# Salvando resultados:
resultados$EQM[resultados$modelo == "Shrinkage"] <- EQM_lasso
resultados$R_squared[resultados$modelo == "Shrinkage"] <- r2
```

## Modelo 3

Random Forest

```{r}
# Fit


# Predição


# Calculo EQM
EQM <- 

# Calculo R quadrado
r2 <- 

# Salvando resultados:
resultados$EQM[resultados$modelo == "modelo"] <- EQM
resultados$R_squared[resultados$modelo == "modelo"] <- r2
```

## Modelo 4

Boosting

```{r}
# Fit


# Predição


# Calculo EQM
EQM <- 

# Calculo R quadrado
r2 <- 

# Salvando resultados:
resultados$EQM[resultados$modelo == "modelo"] <- EQM
resultados$R_squared[resultados$modelo == "modelo"] <- r2
```
